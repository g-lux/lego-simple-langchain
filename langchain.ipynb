{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an instance of the OpenAI class with the API key from the environment variables\n",
    "llm = OpenAI(openai_api_key=os.environ[\"OPENAI_API_KEY\"], temperature=0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The meaning of life is a philosophical question that has been debated for centuries. Some believe that the meaning of life is to find happiness and fulfillment, while others believe it is to fulfill a certain purpose or destiny. Some see it as a spiritual or religious journey, while others view it as a subjective concept that each individual must define for themselves. Ultimately, the meaning of life is a personal and subjective concept that may differ for each individual.\n"
     ]
    }
   ],
   "source": [
    "text=\"What is the meaning of life?\"\n",
    "\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "\n",
    "llm_huggingface=HuggingFaceHub(huggingfacehub_api_token=os.environ[\"HUGGINGFACEHUB_API_TOKEN\"],repo_id=\"google/flan-t5-large\", model_kwargs={\"temperature\":0,\"max_length\":64})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the difference in output between OpenAI and Flan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love\n"
     ]
    }
   ],
   "source": [
    "output=llm_huggingface.predict(\"What is the meaning of life?\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates and LLM Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the capital of this country: USA'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template=PromptTemplate(input_variables=['country],'],\n",
    "                               template=\"Tell me the capital of this country: {country}\")\n",
    "\n",
    "prompt_template.format(country=\"USA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nWashington, D.C.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(prompt_template.format(country=\"USA\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instead of calling predict directly, we can use chains to link multiple actions together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nWashington, D.C.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain=LLMChain(llm=llm, prompt=prompt_template)\n",
    "chain.run(\"USA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining multiple chains using simple sequential chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chain #1: Ask for the capital of a country\n",
    "capital_prompt=PromptTemplate(input_variables=['country'],\n",
    "                            template=\"Tell me the capital of this country: {country}\")\n",
    "\n",
    "capital_chain=LLMChain(llm=llm, prompt=capital_prompt)\n",
    "\n",
    "#Chain #2: Ask for popular destinations in a capital\n",
    "destinations_prompt=PromptTemplate(input_variables=['capital'],\n",
    "                                template=\"Tell me a popular destinations in {capital}\")\n",
    "\n",
    "destinations_chain=LLMChain(llm=llm, prompt=destinations_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. Old Town (Stare Miasto)\\n2. Royal Castle (Zamek Królewski)\\n3. Palace of Culture and Science (Pałac Kultury i Nauki)\\n4. Lazienki Park (Park Łazienkowski)\\n5. Warsaw Uprising Museum (Muzeum Powstania Warszawskiego)\\n6. Wilanów Palace (Pałac w Wilanowie)\\n7. Łazienki Palace (Pałac Łazienkowski)\\n8. Copernicus Science Centre (Centrum Nauki Kopernik)\\n9. POLIN Museum of the History of Polish Jews (Muzeum Historii Żydów Polskich)\\n10. Warsaw Zoo (Ogród Zoologiczny w Warszawie)'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "#now combine the two chains\n",
    "sequential_chain=SimpleSequentialChain(chains=[capital_chain, destinations_chain])\n",
    "\n",
    "#run the combined chain using Poland as the country\n",
    "sequential_chain.run(\"Poland\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chain #1: Ask for the capital of a country\n",
    "\n",
    "#Prompt for the capital\n",
    "capital_prompt=PromptTemplate(input_variables=['country'],\n",
    "                            template=\"Tell me the capital of this country: {country}\")\n",
    "\n",
    "#Create the chain and output the result for capital\n",
    "capital_chain=LLMChain(llm=llm, prompt=capital_prompt,output_key=\"capital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chain #2: Ask for popular destinations in a capital\n",
    "\n",
    "#Prompt for the popular destinations\n",
    "destinations_prompt=PromptTemplate(input_variables=['capital'],\n",
    "                                template=\"Tell me a popular destinations in {capital}\")\n",
    "\n",
    "#Create the chain and output the result for destinations\n",
    "destinations_chain=LLMChain(llm=llm, prompt=destinations_prompt, output_key=\"destinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "chain=SequentialChain(chains=[capital_chain, destinations_chain],\n",
    "                      input_variables=[\"country\"],\n",
    "                      output_variables=[\"capital\", \"destinations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': 'Poland', 'capital': '\\n\\nWarsaw', 'destinations': ', Poland'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({\"country\":\"Poland\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatmodels with ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatllm=ChatOpenAI(openai_api_key=os.environ[\"OPENAI_API_KEY\"],temperature=0.6,model='gpt-3.5-turbo') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1. \"Why did the AI go to therapy? It had too many unresolved loops!\"\\n\\n2. \"Why did the AI get a job at the bakery? It kneaded a change of byte!\"\\n\\n3. \"Why did the AI cross the road? To optimize its path-finding algorithm!\"\\n\\n4. \"Why did the AI start a band? It wanted to make some byte-sized hits!\"\\n\\n5. \"Why did the AI fail the math test? It couldn\\'t differentiate between a calculator and a toaster!\"\\n\\n6. \"Why did the AI start dating a microwave? It wanted to heat things up in its love life!\"\\n\\n7. \"Why did the AI become a stand-up comedian? It wanted to crack jokes faster than its processing speed!\"\\n\\n8. \"Why did the AI become a chef? It wanted to serve up some byte-iful dishes!\"\\n\\n9. \"Why did the AI become a detective? It wanted to solve crimes faster than Sherlock Holmes 2.0!\"\\n\\n10. \"Why did the AI become a personal trainer? It wanted to help people get fit and byte-sized!\"')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm([\n",
    "    SystemMessage(content=\"You are a comedian AI assistant\"),\n",
    "    HumanMessage(content=\"Please provide some comedy punchlines on AI\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template + LLM + Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Commaseperatedoutput(BaseOutputParser):\n",
    "    def parse(self, text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"Your a helpful assistant. When the user provides any input, you should generate 5 synonyms for the input and provide them to the user.\"\n",
    "human_template = \"{text}\"\n",
    "chatprompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template)\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=chatprompt|chatllm|Commaseperatedoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sure! Here are 5 synonyms for \"dog\":\\n\\n1. Canine\\n2. Pooch\\n3. Hound\\n4. Mut\\n5. Fido']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"dog\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
